<!--
@author: è®¸ä¿Šæ°
@desc: å¤§æ–‡ä»¶ä¸Šä¼ 
@date: 2023/06/26
-->
<template>
	<div class="large-file-upload">
		<input type="file" ref="inputRef" @change="changeFile" />

		<div>----------------------------</div>

		<div>æ–‡ä»¶ <span class="bigFileC">ğŸ“</span> åˆ†ä¸ºäº†{{ chunksCount }}ç‰‡</div>

		<div>----------------------------</div>

		<div>è®¡ç®—æ–‡ä»¶çš„hashå€¼è¿›åº¦</div>
		<progress :value="hashProgress" max="100"></progress> {{ hashProgress }}%
		<div class="r">hashå€¼ä¸º: {{ fileHash }}</div>

		<div>----------------------------</div>

		<div>ä¸Šä¼ æ–‡ä»¶çš„è¿›åº¦</div>
		<progress :value="fileProgress" max="100"></progress> {{ fileProgress }}%
		<div class="r" v-show="fileProgress == 100">æ–‡ä»¶ä¸Šä¼ å®Œæˆ</div>
	</div>
</template>

<script>
import SparkMD5 from 'spark-md5'

export default {
	name: 'LargeFileUpload',

	data() {
		return {
			chunksCount: 0,
			hashProgress: 0,
			fileProgress: 0,

			fileHash: '',
		}
	},

	methods: {
		async changeFile() {
			const file = this.$refs.inputRef.files[0] // æ‹¿åˆ°æ–‡ä»¶
			const chunks = this.sliceFile(file) // ç»™æ–‡ä»¶åˆ‡ç‰‡
			this.fileHash = await this.getFileMd5(chunks)
			this.chunksCount = chunks.length
		},

		sliceFile(file, chunkSize = 1 * 1024 * 1024) {
			const result = []
			// ä»ç¬¬ 0 å­—èŠ‚å¼€å§‹åˆ‡å‰², ä¸€æ¬¡åˆ‡å‰² 1 * 1024 * 1024 å­—èŠ‚(1MB)
			for (let i = 0; i < file.size; i += chunkSize) {
				result.push(file.slice(i, i + chunkSize))
			}
			return result
		},

		getFileMd5(chunks, progressCallbackFn) {
			return new Promise((resolve, reject) => {
				let currentChunk = 0 // å‡†å¤‡ä»ç¬¬0å—å¼€å§‹è¯»
				let spark = new SparkMD5.ArrayBuffer() // å®ä¾‹åŒ–spark-md5
				let fileReader = new FileReader() // å®ä¾‹åŒ–æ–‡ä»¶é˜…è¯»å™¨

				fileReader.onerror = reject // å…œä¸€ä¸‹é”™

				fileReader.onload = e => {
					// progressCallbackFn(Math.ceil((currentChunk / chunks.length) * 100)) // æŠ›å‡ºä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå‘ŠçŸ¥è¿›åº¦
					spark.append(e.target.result) // å°†äºŒè¿›åˆ¶æ–‡ä»¶è¿½åŠ åˆ°sparkä¸­ï¼ˆå®˜æ–¹æ–¹æ³•ï¼‰
					currentChunk = currentChunk + 1 // è¿™ä¸ªè¯»å®Œå°±åŠ 1ï¼Œè¯»å–ä¸‹ä¸€ä¸ªblob
					// è‹¥æœªè¯»å–åˆ°æœ€åä¸€å—ï¼Œå°±ç»§ç»­è¯»å–ï¼›å¦åˆ™è¯»å–å®Œæˆï¼ŒPromiseå¸¦å‡ºç»“æœ
					if (currentChunk < chunks.length) {
						fileReader.readAsArrayBuffer(chunks[currentChunk])
					} else {
						resolve(spark.end()) // resolveå‡ºå»å‘ŠçŸ¥ç»“æœ spark.endå®˜æ–¹api
					}
				}
				// æ–‡ä»¶è¯»å–å™¨çš„readAsArrayBufferæ–¹æ³•å¼€å§‹è¯»å–æ–‡ä»¶ï¼Œä»blobæ•°ç»„ä¸­çš„ç¬¬0é¡¹å¼€å§‹
				fileReader.readAsArrayBuffer(chunks[currentChunk])
			})
		},
	},
}
</script>

<style lang="scss" scope></style>
